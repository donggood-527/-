{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import time\n",
    "import json\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "[['2020-08-09', '우리\\U0001f90d👫🏻연기중인 나와 어색한 @no_hooni ㅋㅋ#충주#충주호#캠핑#여행에미치다', 0, ['#충주', '#충주호', '#캠핑', '#여행에미치다']], ['2020-08-09', '‘여기는 경주,황화코스모스’공간이 주는 힘이라는 게 정말 대단하구나.이번 주 촬영답사겸 한 바퀴 돌아보니 경주 포인트 구석구석 카메라 들고 나온 사람들이 엄청 많던... 맑았다가 비가 쏟아졌다가 쌍무지개가 떴다가 정말 다이나믹했던 일요일... 입추도 지났고 이제 어서 가을이 오기를 🌿🏷2020년 #경주스냅 유료촬영 가을시즌 예약중입니다.동화같이 예쁜 경주에서 두 분의 이야기를 담아드립니다.‘야외스냅’과 ‘본식스냅’을 함께 예약하실 경우 10%할인혜택 드립니다. 🔜자세한 상품 구성 안내는 프로필에 기재된 블로그 참고해주세요.🏷 ‘경주웨딩’ 그리고 봄부터 겨울까지 함께 담는 특별한 커스터마이징 #사계절스냅 문의까지 언제나 환영합니다. 🙋🏻\\u200d♀️📸🙋🏻\\u200d♂️. 경주를 사랑하는...아름다운 경주에 살고 경주를 담습니다.어쩌다 경주, 다시 또 경주!.※ 모든 이미지의 저작권은 포시즌스엘스냅에게 있으며 불펌 및 사진도용시에는 법적처벌을 받을 수 있습니다 ※Copyrights ⓒ Fourseasons-Lsnap All pictures can’t be copied without permission.————————————————————————🌱촬영 희망 날짜와 자세한 문의는 DM or 카카오톡 플러스친구 ‘포시즌스엘스냅’ 연락주세요📮🌱포시즌스엘스냅과 함께 해 주시는 모든 고객님 감사합니다🥳👏🏻————————————————————————---#포시즌스엘스냅 #경북여행 #경주 #경주여행 #여름휴가 #황화코스모스 #분황사 #경주가볼만한곳 #경주웨딩스냅 #경주본식스냅 #셀프웨딩 #커플스냅 #가족스냅 #풍경 #감성사진 #여행에미치다 #색감 #슬기로운캐논생활 #국내여행 #캐논이미지스토밍 #canon1dxmarkii #koreabyme #travelgram_korea #canon #gyeongju #beautifuldestinations #ig_nature', '531', ['#경주스냅', '#사계절스냅', '#포시즌스엘스냅', '#경북여행', '#경주', '#경주여행', '#여름휴가', '#황화코스모스', '#분황사', '#경주가볼만한곳', '#경주웨딩스냅', '#경주본식스냅', '#셀프웨딩', '#커플스냅', '#가족스냅', '#풍경', '#감성사진', '#여행에미치다', '#색감', '#슬기로운캐논생활', '#국내여행', '#캐논이미지스토밍', '#canon1dxmarkii', '#koreabyme', '#travelgram_korea', '#canon', '#gyeongju', '#beautifuldestinations', '#ig_nature']]]\n"
     ]
    }
   ],
   "source": [
    "#함수 작성\n",
    "def insta_searching(word):  #word라는 매개변수를 받는 insta_searching 이라는 함수 생성\n",
    "    url = 'https://www.instagram.com/explore/tags/' + word\n",
    "    return url\n",
    " \n",
    "#열린 크롬으로 개발자 도구 활용하여 첫번째 게시물 태그 확인 (<div class=\"_9AhH0\"></div>)\n",
    "#첫번째 게시물 찾아 클릭 함수 만들기\n",
    "\n",
    "import time\n",
    " \n",
    "def select_first(driver):\n",
    "    first = driver.find_element_by_css_selector('div._9AhH0') #find_element_by_css_selector 함수를 사용해 요소 찾기\n",
    "    first.click()\n",
    "    time.sleep(3) #로딩을 위해 3초 대기\n",
    " \n",
    "#본문 내용, 작성 일시, 위치 정보 및 해시태그(#) 추출\n",
    " \n",
    "import re\n",
    " \n",
    "def get_content(driver):\n",
    "    # 1. 현재 페이지의 HTML 정보 가져오기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    # 2. 본문 내용 가져오기\n",
    "    try:                                         #여러 태그중 첫번째([0]) 태그를 선택  \n",
    "        content = soup.select('div.C4VMK > span')[0].text #첫 게시글 본문 내용이 <div class=\"C4VMK\"> 임을 알 수 있다.\n",
    "                                #태그명이 div, class명이 C4VMK인 태그 아래에 있는 span 태그를 모두 선택.\n",
    "    except:\n",
    "        content = ' ' \n",
    "        \n",
    "    # 3. 본문 내용에서 해시태그 가져오기(정규표현식 활용)\n",
    "    tags = re.findall(r'#[^\\s#,\\\\]+', content) \n",
    "        # content 변수의 본문 내용 중 #으로 시작하며, #뒤에 연속된 문자(공백이나 #, \\ 기호가 아닌 경우)를 모두 찾아 tags 변수에 저장\n",
    "    \n",
    "    # 4. 작성 일자 가져오기\n",
    "    try:\n",
    "        date = soup.select('time._1o9PC.Nzb55')[0]['datetime'][:10] #앞에서부터 10자리 글자\n",
    "    except:\n",
    "        date = ''\n",
    " \n",
    "    # 5. 좋아요 수 가져오기\n",
    "    try:\n",
    "        like = soup.select('div.Nm9Fw > button')[0].text[4:-1] \n",
    "    except:\n",
    "        like = 0\n",
    "        \n",
    "    # 6. 위치 정보 가져오기\n",
    "    try:\n",
    "        place = soup.select('div.JF9hh')[0].text\n",
    "    except:\n",
    "        place = ''\n",
    "    \n",
    "    # 7. 수집한 정보 저장하기\n",
    "    data = [date, content, like, tags]\n",
    "    return data    \n",
    "\n",
    "# content, date, like, place\n",
    "\n",
    "def move_next(driver):\n",
    "    right = driver.find_element_by_css_selector('a._65Bje.coreSpriteRightPaginationArrow') \n",
    "    right.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "# 1. 크롬으로 인스타그램 - '국내여행지추천' 검색\n",
    "driver = wd.Chrome(executable_path='./chromedriver')\n",
    "word = '국내여행'\n",
    "url = insta_searching(word)\n",
    "driver.get(url) \n",
    "time.sleep(4)\n",
    "\n",
    "# 2. 로그인 하기\n",
    "login_section = '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[3]/div/span/a[1]/button'\n",
    "driver.find_element_by_xpath(login_section).click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "elem_login = driver.find_element_by_name(\"username\")\n",
    "elem_login.clear()\n",
    "elem_login.send_keys('goeunseong12')\n",
    " \n",
    "elem_login = driver.find_element_by_name('password')\n",
    "elem_login.clear()\n",
    "elem_login.send_keys('gp941105**')\n",
    " \n",
    "time.sleep(1)\n",
    " \n",
    "xpath = \"\"\"//*[@id=\"loginForm\"]/div/div[3]/button/div\"\"\"\n",
    "driver.find_element_by_xpath(xpath).click()\n",
    " \n",
    "time.sleep(4)\n",
    "\n",
    "xpath1 = \"\"\"//*[@id=\"react-root\"]/section/main/div/div/div/div/button\"\"\"\n",
    "\n",
    "driver.find_element_by_xpath(xpath1).click()\n",
    "time.sleep(4)\n",
    "\n",
    "# 3. 검색페이지 접속하기\n",
    "driver.get(url)\n",
    "time.sleep(4)\n",
    "\n",
    "# 4. 첫번째 게시글 열기\n",
    "select_first(driver)\n",
    "\n",
    "# 5. 비어있는 변수(results) 만들기\n",
    "results = []\n",
    " \n",
    "# 여러 게시물 크롤링하기\n",
    "target = 1000 #크롤링할 게시물 수\n",
    "for i in range(target):\n",
    "    data = get_content(driver) #게시물 정보 가져오기\n",
    "    results.append(data)\n",
    "    move_next(driver)\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "\n",
    "    \n",
    "print(results[:2])\n",
    "\n",
    "\n",
    "# #data = [content, date, like, place, tags]\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('여행지.csv',index=False, encoding='utf-16')\n",
    "\n",
    "              \n",
    "# # df['content']= content\n",
    "# # df['date'] = date\n",
    "# # df['like'] = like\n",
    "# # df['place'] = place\n",
    "# df['tags'] = tags\n",
    "# # df['date'] = pd.to_datetime(df['date']) \n",
    "# df.to_csv('여행지.csv',index=False)\n",
    "# return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['date', 'content', 'like', 'tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('국내여행인스타.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
